{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import require libraries and dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view feature names of the dataset\n",
    "iris_dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view target of the dataset\n",
    "iris_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define features and target objects\n",
    "x_feature = iris_dataset.data\n",
    "y_target = iris_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object with new values for prediction\n",
    "x_new = [[3,5,4,1],[5,3,4,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the logistic regression estimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aabha\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the data into the logistic regression estimator\n",
    "logReg.fit(x_feature,y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict the outcome using Logistic regression estimator\n",
    "logReg.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library for model persistence\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x80\\x03csklearn.linear_model._logistic\\nLogisticRegression\\nq\\x00)\\x81q\\x01}q\\x02(X\\x07\\x00\\x00\\x00penaltyq\\x03X\\x02\\x00\\x00\\x00l2q\\x04X\\x04\\x00\\x00\\x00dualq\\x05\\x89X\\x03\\x00\\x00\\x00tolq\\x06G?\\x1a6\\xe2\\xeb\\x1cC-X\\x01\\x00\\x00\\x00Cq\\x07G?\\xf0\\x00\\x00\\x00\\x00\\x00\\x00X\\r\\x00\\x00\\x00fit_interceptq\\x08\\x88X\\x11\\x00\\x00\\x00intercept_scalingq\\tK\\x01X\\x0c\\x00\\x00\\x00class_weightq\\nNX\\x0c\\x00\\x00\\x00random_stateq\\x0bNX\\x06\\x00\\x00\\x00solverq\\x0cX\\x05\\x00\\x00\\x00lbfgsq\\rX\\x08\\x00\\x00\\x00max_iterq\\x0eKdX\\x0b\\x00\\x00\\x00multi_classq\\x0fX\\x04\\x00\\x00\\x00autoq\\x10X\\x07\\x00\\x00\\x00verboseq\\x11K\\x00X\\n\\x00\\x00\\x00warm_startq\\x12\\x89X\\x06\\x00\\x00\\x00n_jobsq\\x13NX\\x08\\x00\\x00\\x00l1_ratioq\\x14NX\\x08\\x00\\x00\\x00classes_q\\x15cnumpy.core.multiarray\\n_reconstruct\\nq\\x16cnumpy\\nndarray\\nq\\x17K\\x00\\x85q\\x18C\\x01bq\\x19\\x87q\\x1aRq\\x1b(K\\x01K\\x03\\x85q\\x1ccnumpy\\ndtype\\nq\\x1dX\\x02\\x00\\x00\\x00i4q\\x1eK\\x00K\\x01\\x87q\\x1fRq (K\\x03X\\x01\\x00\\x00\\x00<q!NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq\"b\\x89C\\x0c\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00q#tq$bX\\x05\\x00\\x00\\x00coef_q%h\\x16h\\x17K\\x00\\x85q&h\\x19\\x87q\\'Rq((K\\x01K\\x03K\\x04\\x86q)h\\x1dX\\x02\\x00\\x00\\x00f8q*K\\x00K\\x01\\x87q+Rq,(K\\x03h!NNNJ\\xff\\xff\\xff\\xffJ\\xff\\xff\\xff\\xffK\\x00tq-b\\x89C`>\\xcfj\\x90\\xac\\xd8\\xda\\xbf\\xf2\\x1a\\xder\\xe4\\xf5\\xee?\\x8a\\xe1y\\xd7\\x15*\\x04\\xc0\\xcb\\x8do\\xafnY\\xf1\\xbf=\\xab\\xa3\\x07\\xfa\\x01\\xe1?l\\x07-\\x94\\x86)\\xd4\\xbf\\xba\\xbf\\x06\\xe7O\\xba\\xc9\\xbfx\\xe7\\x93\\x8anT\\xee\\xbf!\\x19r\\xfb\\x1d\\xad\\xbc\\xbf\\xd0\\x95\\xc7(!\\xe1\\xe4\\xbf\\xd0M\\xea\\xd5\\xba\\xc5\\x05@\\xd6\\xc0\\\\\\xfa\\xd2A\\x00@q.tq/bX\\n\\x00\\x00\\x00intercept_q0h\\x16h\\x17K\\x00\\x85q1h\\x19\\x87q2Rq3(K\\x01K\\x03\\x85q4h,\\x89C\\x18\\x1c+\\xdd\\x00\\x15\\xaf#@\\x7f2\\x14 \\x04\\xc1\\x01@\\xa58\\xe2\\x08V\\x1f(\\xc0q5tq6bX\\x07\\x00\\x00\\x00n_iter_q7h\\x16h\\x17K\\x00\\x85q8h\\x19\\x87q9Rq:(K\\x01K\\x01\\x85q;h \\x89C\\x04d\\x00\\x00\\x00q<tq=bX\\x10\\x00\\x00\\x00_sklearn_versionq>X\\x06\\x00\\x00\\x000.22.1q?ub.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use dumps method to persist the model\n",
    "persist_model = pkl.dumps(logReg)\n",
    "persist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aabha\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['regresfilename.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use joblib.dump to persist the model to a file\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(logReg,'regresfilename.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use joblib.load to persist the model to a file\n",
    "#create new estimator from the saved model\n",
    "new_logreg_estimator = joblib.load('regresfilename.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the new estimator\n",
    "new_logreg_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate and use new estimator to predict\n",
    "new_logreg_estimator.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
